{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-triassi/ai-projects-472/blob/main/Project%203/Project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pR0zjGgmMNB"
      },
      "source": [
        "# Import Dependencies\n",
        "from gensim.downloader import load\n",
        "from gensim.models import word2vec\n",
        "from gensim.similarities import SoftCosineSimilarity\n",
        "import pandas as pd\n",
        "import csv\n",
        "import random # XD RaWR L0L im so R4nDOM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV-652Fxm0XM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "663b7cfe-5d2e-4871-e936-98ece02a86ef"
      },
      "source": [
        "# Grab dataset csv\n",
        "!wget https://raw.githubusercontent.com/m-triassi/ai-projects-472/main/Project%203/synonyms.csv?token=ACIA3M7EM7SLE5PLCHH3CRTBWZZ2S -O synonyms.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-07 04:11:27--  https://raw.githubusercontent.com/m-triassi/ai-projects-472/main/Project%203/synonyms.csv?token=ACIA3M7EM7SLE5PLCHH3CRTBWZZ2S\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4415 (4.3K) [text/plain]\n",
            "Saving to: ‘synonyms.csv’\n",
            "\n",
            "synonyms.csv        100%[===================>]   4.31K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-07 04:11:27 (47.5 MB/s) - ‘synonyms.csv’ saved [4415/4415]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4sCATDMv-8z"
      },
      "source": [
        "headers = [\"question\",\"answer\",\"A\",\"B\",\"C\",\"D\"]\n",
        "synonyms = pd.read_csv(\"/content/synonyms.csv\", header=None, names=headers)[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-dX9YkisJOa"
      },
      "source": [
        "# Define similarity run method\n",
        "# accepts model to be used\n",
        "def similarity_all(model: word2vec) -> list:\n",
        "  details = []\n",
        "  ## iterates over synonyms\n",
        "  for s in synonyms.iterrows():\n",
        "    ## Catch if the word is not present, and perfrom a guess.\n",
        "    guesses = {}\n",
        "    label = \"\"\n",
        "    guess = \"\"\n",
        "    if not s[1][\"question\"] in model.vocab:\n",
        "      guess = s[1][random.choice([\"A\", \"B\", \"C\", \"D\"])]\n",
        "      label = \"guess\"\n",
        "  \n",
        "    for q in [\"A\", \"B\", \"C\", \"D\"]:\n",
        "      try:\n",
        "        guesses[q] = (model.similarity(s[1][\"question\"], s[1][q]))\n",
        "      except KeyError:\n",
        "        continue\n",
        "\n",
        "    if guesses:\n",
        "      # sort the guesses by their value\n",
        "      max_key = max(guesses, key=guesses.get)\n",
        "      guess = s[1][max_key]\n",
        "    elif (label is not \"guess\"):\n",
        "      # none of the guess-words were in the vocab, just guess something..\n",
        "      guess = model.most_similar(positive=s[1][\"question\"], topn=1)[0]\n",
        "      label = \"guess\"\n",
        "    \n",
        "    if label is not \"guess\" and guess == s[1][\"answer\"]:\n",
        "      label = \"correct\"\n",
        "    elif label is not \"guess\":\n",
        "      label = \"wrong\"\n",
        "\n",
        "    # build the details array\n",
        "    details.append([s[1][\"question\"], s[1][\"answer\"], guess, label])\n",
        "  \n",
        "  return details\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyTVeOXUsxe5"
      },
      "source": [
        "# Build analysis for a particular run function\n",
        "## could just read the details csv and generate a new line in analysis.csv\n",
        "def analyze_details(model: word2vec, details: pd.DataFrame, model_name):\n",
        "  analysis = []\n",
        "  correct_count = 0\n",
        "  guess_count = 0\n",
        "  for d in details.iterrows():\n",
        "    correct_count += d[1]['label'] == \"correct\"\n",
        "    guess_count += d[1]['label'] == \"guess\"\n",
        "\n",
        "  V = 80 - guess_count\n",
        "  analysis_header = ['model_name', 'vocab_size', 'C', 'V', 'accuracy']\n",
        "  analysis_data = [model_name, len(model.vocab), correct_count, V, correct_count/V]\n",
        "  pd.DataFrame([analysis_data], columns=analysis_header).to_csv('analysis.csv', mode=\"a\", header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQhuIXeyDEjA"
      },
      "source": [
        "def generate_reports(model: word2vec, label):\n",
        "  details = similarity_all(model)\n",
        "  detail_headers = [\"question-word\", \"answer-word\", \"guess-word\", \"label\"]\n",
        "  detail_data = pd.DataFrame(details, columns=detail_headers)\n",
        "\n",
        "  detail_data.to_csv(f\"{label}-details.csv\")\n",
        "  analyze_details(model, detail_data, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvenl_E3aOU8"
      },
      "source": [
        "## Task 1\n",
        "Load the Word2Vec google news pretrained model, evaluate performance using gold standard test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXZ2x6Z-s9BU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17d3dc6f-7f76-4e2f-ba32-708dcfebe2ff"
      },
      "source": [
        "# Load google-news-300 pre-trained model\n",
        "model = load('word2vec-google-news-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOEete_lt2nk"
      },
      "source": [
        "# Test Word2Vec model, save details, generate analysis\n",
        "generate_reports(model, \"word2vec-google-news-300\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1nb2IP-abGt"
      },
      "source": [
        "## Task 2\n",
        "Repeat analysis for 4 more models. 2 with same embedding but different corpus, and 2 with differnt embedding but same corpus.\n",
        "\n",
        "Leverage functions written for task 1.\n",
        "\n",
        "Models: \n",
        "- glove-twitter-50 vs glove-wiki-gigaword-50\n",
        "- glove-wiki-gigaword-100 vs glove-wiki-gigaword-300 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkfcPoLkB72U",
        "outputId": "c2b5a04e-608b-4715-9633-ddac7a9df4be"
      },
      "source": [
        "model = load('glove-twitter-50')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 199.5/199.5MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfb1DImPB7_B"
      },
      "source": [
        "# Test Word2Vec model, save details, generate analysis\n",
        "generate_reports(model, \"glove-twitter-50\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK6yz0syB8GW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba8a17b-be3c-47e3-8775-bdd4ade6e97d"
      },
      "source": [
        "model = load('glove-wiki-gigaword-50')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoDcv9IEB8Ny"
      },
      "source": [
        "# Test Word2Vec model, save details, generate analysis\n",
        "generate_reports(model, \"glove-wiki-gigaword-50\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naSZxkWwB8Wb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddde57ee-f6a6-45f3-8e3d-a00c1d1ed24e"
      },
      "source": [
        "model = load('glove-wiki-gigaword-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDDWn85WCmC9"
      },
      "source": [
        "# Test Word2Vec model, save details, generate analysis\n",
        "generate_reports(model, \"glove-wiki-gigaword-300\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ucE05cOVRsN",
        "outputId": "0a5ea4ac-356e-4ecc-a854-3acc52c27679"
      },
      "source": [
        "model = load(\"glove-wiki-gigaword-100\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvR-nU5xVVyG"
      },
      "source": [
        "# Test Word2Vec model, save details, generate analysis\n",
        "generate_reports(model, \"glove-wiki-gigaword-100\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}